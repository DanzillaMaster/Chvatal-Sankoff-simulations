import numpy as np
from scipy.stats import norm

# ------------------------------------------------------------------
# 1. ВВЕДИТЕ свои данные ------------------------------------------------
#    n   — массив длин строк
#    y   — массив усреднённых оценок γ2(n)
#    se  — массив стандартных ошибок этих оценок
# ------------------------------------------------------------------
n  = np.array([6_250, 12_500, 25_000, 50_000, 100_000], dtype=float)
y  = np.array([0.809953,  0.810762,  0.811289, 0.811619, 0.811835])
std = np.array([0.001637, 0.001082, 0.000720, 0.000481, 0.000324])
se = std / np.sqrt(n)

# ------------------------------------------------------------------
# 2. ФОРМИРУЕМ дизайн-матрицу X (интерцепт + 1/√n) и веса W
# ------------------------------------------------------------------
x = 1.0 / np.sqrt(n)                    # регрессор n^{-1/2}
X = np.column_stack((np.ones_like(x), x))  # k × 2
w = 1.0 / se**2                                # вектор весов w_i = 1/SE_i²
W = np.diag(w)

# ------------------------------------------------------------------
# 3. ОЦЕНКА коэффициентов взвешенной МНК
#    β = (Xᵀ W X)⁻¹ Xᵀ W y  →  β = (â, b̂)
# ------------------------------------------------------------------
XtWX      = X.T @ W @ X
XtWy      = X.T @ W @ y
beta_hat  = np.linalg.solve(XtWX, XtWy)   # более надёжно, чем inv
a_hat, b_hat = beta_hat

# ------------------------------------------------------------------
# 4. КОВАРИАЦИЯ оценок  &  стандартная ошибка â
# ------------------------------------------------------------------
cov_beta  = np.linalg.inv(XtWX)
var_a_hat = cov_beta[0, 0]
se_a_hat  = np.sqrt(var_a_hat)

# ------------------------------------------------------------------
# 5. 95-% ДОВЕРИТЕЛЬНЫЙ ИНТЕРВАЛ для γ₂  (предел = â)
# ------------------------------------------------------------------
z = norm.ppf(0.995)
ci_low, ci_high = a_hat - z*se_a_hat, a_hat + z*se_a_hat

# ------------------------------------------------------------------
# 6. ДИАГНОСТИКА остатков (при желании)
# ------------------------------------------------------------------
residuals = y - (a_hat + b_hat*x)
print("остатки:", residuals)

# ------------------------------------------------------------------
# 7. ВЫВОД
# ------------------------------------------------------------------
print(f"Оценка γ₂  (â)      : {a_hat:.6f}")
print(f"Ст. ошибка â         : {se_a_hat:.2e}")
print(f"99% интервал         : [{ci_low:.6f}, {ci_high:.6f}]")
print(f"Оценка b             : {b_hat:.6f}")

y_hat  = X @ beta_hat
resid  = y - y_hat

y_bar_w = np.sum(w * y) / np.sum(w)            # взвешенное среднее
tss_w   = np.sum(w * (y - y_bar_w)**2)         # total sum of squares
rss_w   = np.sum(w * resid**2)                 # residual sum of squares
r2_w    = 1 - rss_w / tss_w

print(f"Взвешенный R²        : {r2_w:.6f}")